{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validate $\\rightarrow$ Train, Test\n",
    "\n",
    "In this exercise, you will perform empirical comparison of the results of a ten-fold cross-validated model with a fully trained model.\n",
    "\n",
    "## Notes and Guidelines\n",
    "* Read a dataset and use it for a classification task.\n",
    "* Construct a Gaussian Naive Bayes classifier and fit it to the phoneme dataset provided.\n",
    "* Save and re-load a trained classifier.\n",
    "* Compare K-fold cross-validation scores with the success rate of a fully-trained model.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "* Dataset acquired from [KEEL](http://sci2s.ugr.es/keel/dataset.php?cod=105), an excellent resource for finding 'toy' datasets (and a few more serious ones).\n",
    "    * A description of the dataset is provided at the above link - **read it.**\n",
    "    * Excerpt: \n",
    "    *The aim of this dataset is to distinguish between nasal (class 0) and oral sounds (class 1).\n",
    "    The class distribution is 3,818 samples in class 0 and 1,586 samples in class 1.\n",
    "    The phonemes are transcribed as follows: sh as in she, dcl as in dark, iy as the vowel in she, aa as the vowel in dark, and ao as the first vowel in water.*\n",
    "    \n",
    "* It is not necessary to fully understand the nature or context of the values in the dataset - only that there are five columns of input (featural) data and one column of output (class) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling imports and checking the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# <import the necessary modules here> \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# locate dataset\n",
    "DATASET = '/dsa/data/all_datasets/phoneme.csv'  # phoneme classification dataset\n",
    "assert os.path.exists(DATASET)  # check if the file actually exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing data frame from raw dataset\n",
    "\n",
    "<span style=\"background:yellow\">**Note**</span>: Variable `dataset` should be used for the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (5404, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = pd.read_csv(DATASET, header=0).sample(frac=1)\n",
    "\n",
    "# verify dataset shape\n",
    "print(\"Dataset shape: \", dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aa</th>\n",
       "      <th>Ao</th>\n",
       "      <th>Dcl</th>\n",
       "      <th>Iy</th>\n",
       "      <th>Sh</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.277</td>\n",
       "      <td>1.136</td>\n",
       "      <td>2.468</td>\n",
       "      <td>-0.763</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>1.721</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>3.087</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>0.150</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>0.401</td>\n",
       "      <td>1.813</td>\n",
       "      <td>1.245</td>\n",
       "      <td>0.505</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.174</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.513</td>\n",
       "      <td>1.097</td>\n",
       "      <td>0.886</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Aa     Ao    Dcl     Iy     Sh  Class\n",
       "890   0.277  1.136  2.468 -0.763 -0.410      0\n",
       "2328  1.721  0.578 -0.193 -0.130 -0.100      0\n",
       "5279  3.087 -0.304  0.150 -0.072  0.057      0\n",
       "3650  0.401  1.813  1.245  0.505 -0.234      0\n",
       "344   0.174  0.938  0.513  1.097  0.886      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show first few lines of the dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into training and test sets\n",
    "\n",
    "Split the datasets into training (80%) and testing (20%) sets. \n",
    "\n",
    "The below is only necessary if you are interested in visualizing\n",
    "the data or providing neatly-labeled output within the program.\n",
    "\n",
    "```python\n",
    "# extract labels from column headers\n",
    "phonemes = dataset.columns[0:5].tolist()  # Feature labels\n",
    "labels = {0: 'Nasal', 1: 'Oral'}  # Class labels\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Activity 01:** Extract features and class data from the primary data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = dataset.iloc[:, :-1] \n",
    "y = dataset.iloc[:, -1]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes (X, y):  (4323, 5) (4323,)\n",
      "Testing shapes (X, y):  (1081, 5) (1081,)\n"
     ]
    }
   ],
   "source": [
    "# split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training shapes (X, y): \", X_train.shape, y_train.shape)\n",
    "print(\"Testing shapes (X, y): \", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the classifier and running automated cross-validation\n",
    "\n",
    "---\n",
    "\n",
    "**Activity 02:**\n",
    "\n",
    "* Run a 10-fold cross validation with `GaussianNB` classifier on the training set.\n",
    "* Print the accuracy scores for these 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.75057737 0.77829099 0.78290993 0.74768519 0.75925926 0.76851852\n",
      " 0.73148148 0.74305556 0.7962963  0.77083333]\n",
      "Mean cross-validation accuracy:  0.7628907920622701\n"
     ]
    }
   ],
   "source": [
    "# Your code below this line (Question #02)\n",
    "# --------------------------\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores = cross_val_score(gnb, X_train, y_train, cv=10)\n",
    "\n",
    "# Print accuracy scores for the 10 folds\n",
    "print(\"Cross-validation scores: \", cv_scores)\n",
    "print(\"Mean cross-validation accuracy: \", np.mean(cv_scores))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier and pickling to disk\n",
    "\n",
    "---\n",
    "\n",
    "**Activity 03:** Train the model with all the training instances and store to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code below this line (Question #03)\n",
    "# --------------------------\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Save trained model\n",
    "with open(\"naive_bayes_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(gnb, model_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpickling the model and making predictions\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Activity 04:**\n",
    "* Load the saved model. \n",
    "* Make predictions for the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vs. output shape:\n",
      "(1081, 5) (1081,)\n"
     ]
    }
   ],
   "source": [
    "# Your code below this line (Question #04)\n",
    "# --------------------------\n",
    "\n",
    "# load pickled model\n",
    "with open(\"naive_bayes_model.pkl\", \"rb\") as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "# make predictions with freshly loaded model\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# verify input and output shape are appropriate\n",
    "print(\"Input vs. output shape:\")\n",
    "print(X_test.shape, y_pred.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing final performance comparison\n",
    "\n",
    "**Activity 05:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct guesses: 818\n",
      "Incorrect guesses: 263\n",
      "Percent correct: 75.67067530064755\n",
      "Percent cross-validation score (10 folds, average): 76.289079206227\n"
     ]
    }
   ],
   "source": [
    "# tally up right + wrong 'guesses' by model\n",
    "true, false = 0, 0\n",
    "for i, j in zip(y_test, y_pred):\n",
    "    # print(i, j)\n",
    "    if i == j:\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "\n",
    "# report results numerically and by percentage\n",
    "\n",
    "true_percent = true / (true + false) * 100\n",
    "print(\"Correct guesses: \" + str(true) + \"\\nIncorrect guesses: \" + str(false))\n",
    "print(\"Percent correct: \" + str(true_percent))\n",
    "\n",
    "# compare to average of cross-validation scores\n",
    "\n",
    "avg_cv = np.sum(cv_scores) / len(cv_scores) * 100\n",
    "print(\"Percent cross-validation score (10 folds, average): \" + str(avg_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure performance using sklearn\n",
    "\n",
    "---\n",
    "\n",
    "**Activity 06:**\n",
    "\n",
    "Compute the following on the test set and display:\n",
    " 1. Compute Confusion Matrix\n",
    " 1. Accuracy\n",
    " 1. Precision\n",
    " 1. Recall\n",
    " 1. $F_1$-Score\n",
    " \n",
    "Add additional cells if required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[581 173]\n",
      " [ 90 237]]\n",
      "Accuracy: 0.7567067530064755\n",
      "Precision: 0.5780487804878048\n",
      "Recall: 0.7247706422018348\n",
      "F1-Score: 0.6431478968792401\n"
     ]
    }
   ],
   "source": [
    "# Your code below this line  (Question #06)\n",
    "# --------------------------\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Compute Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Compute Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Compute F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions?\n",
    "\n",
    "---\n",
    "\n",
    "**Activity 07:**\n",
    "\n",
    "How did your trained model perform on the test set relative to your expectations based on the cross-validation?\n",
    "Provide your answer in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add your answer below this comment  (Question #07)\n",
    "# -----------------------------------\n",
    "\n",
    "The trained model performed slightly below the expected accuracy obtained from cross-validation. The 10-fold cross-validation resulted in an average accuracy of 76.29%, while the fully trained model achieved 75.67% accuracy on the test set. The difference is minor, which suggests that the cross-validation estimate provided a reliable assessment of the model’s performance.\n",
    "\n",
    "The confusion matrix highlights that the model correctly classified more nasal sounds (class 0) compared to oral sounds (class 1), indicating an imbalance in precision and recall. The precision (57.80%) for class 1 suggests that when the model predicts an oral sound, it is correct only about 58% of the time. However, the recall (72.48%) indicates that the model is relatively good at identifying oral sounds but still misses some.\n",
    "\n",
    "Overall, the model’s performance aligns reasonably well with cross-validation results, reinforcing that cross-validation is a good technique for estimating the generalization ability of the classifier. The slightly lower accuracy on the test set could be due to variations in the data split, but the difference is within an acceptable range.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "---\n",
    "\n",
    "**Activity 08:**\n",
    "* Run a 10-fold cross validation on a logistic regression classifier.\n",
    "* Print the accuracy scores for these 10 folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.75750577 0.7482679  0.77829099 0.71296296 0.75462963 0.76157407\n",
      " 0.72222222 0.75462963 0.78703704 0.75      ]\n",
      "Mean cross-validation accuracy:  0.7527120220682576\n"
     ]
    }
   ],
   "source": [
    "# Your code below this line  (Question #08)\n",
    "# -----------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize Logistic Regression classifier\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cv_scores_log = cross_val_score(log_reg, X_train, y_train, cv=10)\n",
    "\n",
    "# Print accuracy scores for the 10 folds\n",
    "print(\"Cross-validation scores: \", cv_scores_log)\n",
    "print(\"Mean cross-validation accuracy: \", np.mean(cv_scores_log))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Activity 09:** Compute and display the confusion matrix of the logistic regression model for the test set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[651 103]\n",
      " [172 155]]\n",
      "Accuracy: 0.7456059204440333\n",
      "Precision: 0.6007751937984496\n",
      "Recall: 0.4740061162079511\n",
      "F1-Score: 0.5299145299145298\n"
     ]
    }
   ],
   "source": [
    "# Your code below this line  (Question #09)\n",
    "# -----------------------------------\n",
    "\n",
    "# Train Logistic Regression model on the full training set\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "conf_matrix_log = confusion_matrix(y_test, y_pred_log)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_log)\n",
    "\n",
    "# Compute Accuracy\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "\n",
    "# Compute Precision\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "\n",
    "# Compute Recall\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "\n",
    "# Compute F1-Score\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "print(\"F1-Score:\", f1_log)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Activity 10:** Compare the two models by their confusion matrices; how do you interpret their performance? \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Add your answer below this comment  (Question #10)\n",
    "# -----------------------------------\n",
    "\n",
    "The trained Gaussian Naive Bayes model performed slightly worse on the test set than expected based on the cross-validation results. The 10-fold cross-validation produced an average accuracy of 76.29%, while the fully trained model achieved a 75.67% accuracy on the test set, which is a small drop. The confusion matrix indicates that the model performed better at classifying nasal sounds (class 0) than oral sounds (class 1), as evidenced by a higher recall for class 0 and lower precision for class 1. This suggests that the model had more false positives when predicting oral sounds, though it was relatively successful at identifying most of the oral sounds, as shown by the recall of 72.48%. Overall, this indicates that while the model’s performance aligns well with cross-validation estimates, the slight drop in accuracy on the test set is reasonable and within an acceptable range.\n",
    "\n",
    "In comparison, the logistic regression model, after training on the full dataset, had a lower overall accuracy (74.56%) and exhibited a higher precision for class 1 (oral sounds) at 60.08%, but a significantly lower recall of 47.40%. The confusion matrix of the logistic regression model highlights that it was more prone to false negatives when identifying oral sounds, as reflected by the lower recall value. In contrast, the Naive Bayes model showed a better balance between precision and recall for class 1, though both models struggled with the imbalance between the classes. Thus, while logistic regression showed some improvements in precision, its lower recall for class 1 suggests it is less effective at identifying all instances of oral sounds. This comparison underscores the trade-offs between models, where Naive Bayes offers a more balanced approach in this case, while logistic regression’s higher precision came at the cost of missing more oral sound instances.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!  Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
